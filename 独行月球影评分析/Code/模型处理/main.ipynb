{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T01:19:26.880110Z",
     "iopub.status.busy": "2022-10-18T01:19:26.879798Z",
     "iopub.status.idle": "2022-10-18T01:19:29.157662Z",
     "shell.execute_reply": "2022-10-18T01:19:29.156762Z",
     "shell.execute_reply.started": "2022-10-18T01:19:26.880089Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -U -q paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T01:19:29.159368Z",
     "iopub.status.busy": "2022-10-18T01:19:29.158917Z",
     "iopub.status.idle": "2022-10-18T01:19:31.643438Z",
     "shell.execute_reply": "2022-10-18T01:19:31.642715Z",
     "shell.execute_reply.started": "2022-10-18T01:19:29.159341Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import paddle\n",
    "import paddlenlp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-18T01:19:31.645205Z",
     "iopub.status.busy": "2022-10-18T01:19:31.644456Z",
     "iopub.status.idle": "2022-10-18T01:19:31.723106Z",
     "shell.execute_reply": "2022-10-18T01:19:31.722558Z",
     "shell.execute_reply.started": "2022-10-18T01:19:31.645178Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据类型: <class 'paddlenlp.datasets.dataset.MapDataset'>\n",
      "训练集样例: {'text': '很好看，很喜欢，演技特别棒！！', 'label': 1}\n",
      "验证集样例: {'text': '一般般，没有看出表达的东西', 'label': 0}\n",
      "测试集样例: {'text': '还行 还差3个字', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "# 读取数据，并封装为MapDataSet数据类型\n",
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "def read(data_path): # 读取数据\n",
    "    i = 1\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        next(f)  # 跳过列名\n",
    "        for line in f:\n",
    "            label,text = line.strip().split('\\t')\n",
    "            yield {'text': text, 'label': int(label)}\n",
    "\n",
    "\n",
    "train_ds = load_dataset(read, data_path='./data/data172897/train.txt', lazy=False) # 读取训练集数据\n",
    "dev_ds = load_dataset(read, data_path='./data/data172897/dev.txt', lazy=False)  # 读取开发集数据\n",
    "test_ds = load_dataset(read, data_path='./data/data172897/test.txt', lazy=False) # 读取测试集数据\n",
    "\n",
    "train_ds.label_list=test_ds.label_list=[1,0] #设置数据集标签\n",
    "\n",
    "print(\"数据类型:\", type(train_ds))\n",
    "print(\"训练集样例:\", train_ds[0])\n",
    "print(\"验证集样例:\", dev_ds[0])\n",
    "print(\"测试集样例:\", test_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T01:19:31.724450Z",
     "iopub.status.busy": "2022-10-18T01:19:31.723911Z",
     "iopub.status.idle": "2022-10-18T01:19:34.358972Z",
     "shell.execute_reply": "2022-10-18T01:19:34.358314Z",
     "shell.execute_reply.started": "2022-10-18T01:19:31.724428Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-18 09:19:31,725] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.modeling.ErnieForSequenceClassification'> to load 'ernie-3.0-medium-zh'.\n",
      "[2022-10-18 09:19:31,728] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh/ernie_3.0_medium_zh.pdparams\n",
      "W1018 09:19:31.730484  4914 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W1018 09:19:31.733821  4914 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\n",
      "[2022-10-18 09:19:34,325] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'ernie-3.0-medium-zh'.\n",
      "[2022-10-18 09:19:34,327] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh/ernie_3.0_medium_zh_vocab.txt\n",
      "[2022-10-18 09:19:34,353] [    INFO] - tokenizer config file saved in /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh/tokenizer_config.json\n",
      "[2022-10-18 09:19:34,355] [    INFO] - Special tokens file saved in /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练模型和分词器\n",
    "from paddlenlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"ernie-3.0-medium-zh\" # 预训练模型名称\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_classes=len(train_ds.label_list)) # 加载预训练模型，设置类别数量为当前数据集数量\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name) # 加载预训练模型对应的分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T01:19:34.360427Z",
     "iopub.status.busy": "2022-10-18T01:19:34.360028Z",
     "iopub.status.idle": "2022-10-18T01:19:34.367135Z",
     "shell.execute_reply": "2022-10-18T01:19:34.366559Z",
     "shell.execute_reply.started": "2022-10-18T01:19:34.360402Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 数据处理\n",
    "\n",
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "from paddle.io import DataLoader, BatchSampler\n",
    "from paddlenlp.data import DataCollatorWithPadding\n",
    "\n",
    "# 数据预处理函数，利用分词器将文本转化为整数序列\n",
    "def preprocess_function(examples, tokenizer, max_seq_length, is_test=False):\n",
    "\n",
    "    result = tokenizer(text=examples[\"text\"], max_seq_len=max_seq_length)\n",
    "    if not is_test:\n",
    "        result[\"labels\"] = examples[\"label\"]\n",
    "    return result\n",
    "\n",
    "trans_func = functools.partial(preprocess_function, tokenizer=tokenizer, max_seq_length=256)\n",
    "train_ds = train_ds.map(trans_func)\n",
    "dev_ds = dev_ds.map(trans_func)\n",
    "\n",
    "# collate_fn函数构造，将不同长度序列充到批中数据的最大长度，再将数据堆叠\n",
    "collate_fn = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# 定义BatchSampler，选择批大小和是否随机乱序，进行DataLoader\n",
    "train_batch_sampler = BatchSampler(train_ds, batch_size=128, shuffle=True)\n",
    "dev_batch_sampler = BatchSampler(dev_ds, batch_size=128, shuffle=False)\n",
    "train_data_loader = DataLoader(dataset=train_ds, batch_sampler=train_batch_sampler, collate_fn=collate_fn)\n",
    "dev_data_loader = DataLoader(dataset=dev_ds, batch_sampler=dev_batch_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T01:19:34.368464Z",
     "iopub.status.busy": "2022-10-18T01:19:34.367944Z",
     "iopub.status.idle": "2022-10-18T01:19:34.372252Z",
     "shell.execute_reply": "2022-10-18T01:19:34.371724Z",
     "shell.execute_reply.started": "2022-10-18T01:19:34.368442Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "# Adam优化器、交叉熵损失函数、accuracy评价指标\n",
    "optimizer = paddle.optimizer.AdamW(learning_rate=2e-5, parameters=model.parameters())\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "metric = paddle.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T01:19:34.374915Z",
     "iopub.status.busy": "2022-10-18T01:19:34.374473Z",
     "iopub.status.idle": "2022-10-18T01:19:34.379909Z",
     "shell.execute_reply": "2022-10-18T01:19:34.379377Z",
     "shell.execute_reply.started": "2022-10-18T01:19:34.374894Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 构建验证集evaluate函数\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    for batch in data_loader:\n",
    "        input_ids, token_type_ids, labels = batch['input_ids'], batch['token_type_ids'], batch['labels']\n",
    "\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.numpy())\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "        \n",
    "    accu = metric.accumulate()\n",
    "    print(\"eval loss: %.5f, accuracy: %.5f\" % (np.mean(losses), accu))\n",
    "    model.train()\n",
    "    metric.reset()\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T01:19:34.381046Z",
     "iopub.status.busy": "2022-10-18T01:19:34.380781Z",
     "iopub.status.idle": "2022-10-18T01:24:59.311432Z",
     "shell.execute_reply": "2022-10-18T01:24:59.310581Z",
     "shell.execute_reply.started": "2022-10-18T01:19:34.381026Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10, epoch: 1, batch: 10, loss: 0.46610, accu: 0.84688, speed: 3.12 step/s\n",
      "global step 20, epoch: 1, batch: 20, loss: 0.24254, accu: 0.85430, speed: 7.19 step/s\n",
      "global step 30, epoch: 1, batch: 30, loss: 0.16339, accu: 0.86823, speed: 6.42 step/s\n",
      "global step 40, epoch: 1, batch: 40, loss: 0.22133, accu: 0.87871, speed: 6.38 step/s\n",
      "global step 50, epoch: 1, batch: 50, loss: 0.20629, accu: 0.88734, speed: 6.11 step/s\n",
      "global step 60, epoch: 1, batch: 60, loss: 0.15578, accu: 0.89375, speed: 6.82 step/s\n",
      "global step 70, epoch: 1, batch: 70, loss: 0.09900, accu: 0.90056, speed: 6.34 step/s\n",
      "global step 80, epoch: 1, batch: 80, loss: 0.21836, accu: 0.90430, speed: 7.37 step/s\n",
      "global step 90, epoch: 1, batch: 90, loss: 0.13752, accu: 0.90825, speed: 6.82 step/s\n",
      "global step 100, epoch: 1, batch: 100, loss: 0.13874, accu: 0.91094, speed: 6.56 step/s\n",
      "100 eval loss: 0.16625, accuracy: 0.93538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-18 09:19:56,027] [    INFO] - tokenizer config file saved in ./Model/tokenizer_config.json\n",
      "[2022-10-18 09:19:56,029] [    INFO] - Special tokens file saved in ./Model/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 110, epoch: 1, batch: 110, loss: 0.10387, accu: 0.94453, speed: 1.62 step/s\n",
      "global step 120, epoch: 1, batch: 120, loss: 0.15639, accu: 0.93281, speed: 6.60 step/s\n",
      "global step 130, epoch: 1, batch: 130, loss: 0.30000, accu: 0.93073, speed: 7.17 step/s\n",
      "global step 140, epoch: 1, batch: 140, loss: 0.11646, accu: 0.93301, speed: 7.07 step/s\n",
      "global step 150, epoch: 1, batch: 150, loss: 0.13978, accu: 0.93281, speed: 7.37 step/s\n",
      "global step 160, epoch: 1, batch: 160, loss: 0.10998, accu: 0.93372, speed: 6.41 step/s\n",
      "global step 170, epoch: 1, batch: 170, loss: 0.11028, accu: 0.93504, speed: 6.13 step/s\n",
      "global step 180, epoch: 1, batch: 180, loss: 0.16190, accu: 0.93613, speed: 6.34 step/s\n",
      "global step 190, epoch: 1, batch: 190, loss: 0.10121, accu: 0.93628, speed: 6.57 step/s\n",
      "global step 200, epoch: 1, batch: 200, loss: 0.16141, accu: 0.93688, speed: 6.97 step/s\n",
      "200 eval loss: 0.16394, accuracy: 0.93484\n",
      "global step 210, epoch: 1, batch: 210, loss: 0.07769, accu: 0.93984, speed: 1.74 step/s\n",
      "global step 220, epoch: 1, batch: 220, loss: 0.15482, accu: 0.93789, speed: 6.71 step/s\n",
      "global step 230, epoch: 1, batch: 230, loss: 0.19343, accu: 0.93958, speed: 6.61 step/s\n",
      "global step 240, epoch: 1, batch: 240, loss: 0.17971, accu: 0.93672, speed: 6.88 step/s\n",
      "global step 250, epoch: 1, batch: 250, loss: 0.12495, accu: 0.93656, speed: 7.22 step/s\n",
      "global step 260, epoch: 1, batch: 260, loss: 0.10750, accu: 0.93854, speed: 6.79 step/s\n",
      "global step 270, epoch: 1, batch: 270, loss: 0.13169, accu: 0.94040, speed: 7.07 step/s\n",
      "global step 280, epoch: 1, batch: 280, loss: 0.28725, accu: 0.94033, speed: 6.92 step/s\n",
      "global step 290, epoch: 1, batch: 290, loss: 0.21388, accu: 0.94115, speed: 7.52 step/s\n",
      "global step 300, epoch: 1, batch: 300, loss: 0.11892, accu: 0.94172, speed: 7.70 step/s\n",
      "300 eval loss: 0.15316, accuracy: 0.94281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-18 09:20:34,166] [    INFO] - tokenizer config file saved in ./Model/tokenizer_config.json\n",
      "[2022-10-18 09:20:34,168] [    INFO] - Special tokens file saved in ./Model/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 310, epoch: 1, batch: 310, loss: 0.18496, accu: 0.94063, speed: 1.58 step/s\n",
      "global step 320, epoch: 1, batch: 320, loss: 0.11154, accu: 0.94102, speed: 6.82 step/s\n",
      "global step 330, epoch: 1, batch: 330, loss: 0.18363, accu: 0.93776, speed: 6.91 step/s\n",
      "global step 340, epoch: 1, batch: 340, loss: 0.15061, accu: 0.93848, speed: 7.85 step/s\n",
      "global step 350, epoch: 2, batch: 4, loss: 0.18845, accu: 0.93848, speed: 7.08 step/s\n",
      "global step 360, epoch: 2, batch: 14, loss: 0.13058, accu: 0.93818, speed: 7.70 step/s\n",
      "global step 370, epoch: 2, batch: 24, loss: 0.14742, accu: 0.94057, speed: 7.20 step/s\n",
      "global step 380, epoch: 2, batch: 34, loss: 0.19695, accu: 0.94067, speed: 6.87 step/s\n",
      "global step 390, epoch: 2, batch: 44, loss: 0.12494, accu: 0.94215, speed: 7.18 step/s\n",
      "global step 400, epoch: 2, batch: 54, loss: 0.24893, accu: 0.94224, speed: 7.24 step/s\n",
      "400 eval loss: 0.15793, accuracy: 0.93991\n",
      "global step 410, epoch: 2, batch: 64, loss: 0.15922, accu: 0.92969, speed: 1.74 step/s\n",
      "global step 420, epoch: 2, batch: 74, loss: 0.09593, accu: 0.93672, speed: 7.01 step/s\n",
      "global step 430, epoch: 2, batch: 84, loss: 0.09156, accu: 0.94375, speed: 7.25 step/s\n",
      "global step 440, epoch: 2, batch: 94, loss: 0.06740, accu: 0.94570, speed: 7.26 step/s\n",
      "global step 450, epoch: 2, batch: 104, loss: 0.11103, accu: 0.94563, speed: 6.87 step/s\n",
      "global step 460, epoch: 2, batch: 114, loss: 0.19699, accu: 0.94701, speed: 7.08 step/s\n",
      "global step 470, epoch: 2, batch: 124, loss: 0.12217, accu: 0.94665, speed: 6.42 step/s\n",
      "global step 480, epoch: 2, batch: 134, loss: 0.08407, accu: 0.94639, speed: 6.46 step/s\n",
      "global step 490, epoch: 2, batch: 144, loss: 0.08537, accu: 0.94740, speed: 7.03 step/s\n",
      "global step 500, epoch: 2, batch: 154, loss: 0.06940, accu: 0.94914, speed: 6.73 step/s\n",
      "500 eval loss: 0.15929, accuracy: 0.94063\n",
      "global step 510, epoch: 2, batch: 164, loss: 0.08838, accu: 0.94922, speed: 1.75 step/s\n",
      "global step 520, epoch: 2, batch: 174, loss: 0.16163, accu: 0.94531, speed: 7.07 step/s\n",
      "global step 530, epoch: 2, batch: 184, loss: 0.07470, accu: 0.94505, speed: 7.50 step/s\n",
      "global step 540, epoch: 2, batch: 194, loss: 0.14428, accu: 0.94434, speed: 6.39 step/s\n",
      "global step 550, epoch: 2, batch: 204, loss: 0.12660, accu: 0.94578, speed: 6.56 step/s\n",
      "global step 560, epoch: 2, batch: 214, loss: 0.13559, accu: 0.94818, speed: 6.29 step/s\n",
      "global step 570, epoch: 2, batch: 224, loss: 0.07907, accu: 0.94732, speed: 6.63 step/s\n",
      "global step 580, epoch: 2, batch: 234, loss: 0.07890, accu: 0.94717, speed: 6.93 step/s\n",
      "global step 590, epoch: 2, batch: 244, loss: 0.11981, accu: 0.94740, speed: 6.34 step/s\n",
      "global step 600, epoch: 2, batch: 254, loss: 0.13055, accu: 0.94648, speed: 7.48 step/s\n",
      "600 eval loss: 0.15063, accuracy: 0.94100\n",
      "global step 610, epoch: 2, batch: 264, loss: 0.08553, accu: 0.94922, speed: 1.77 step/s\n",
      "global step 620, epoch: 2, batch: 274, loss: 0.22934, accu: 0.94102, speed: 6.92 step/s\n",
      "global step 630, epoch: 2, batch: 284, loss: 0.14693, accu: 0.94661, speed: 6.77 step/s\n",
      "global step 640, epoch: 2, batch: 294, loss: 0.07792, accu: 0.94766, speed: 6.39 step/s\n",
      "global step 650, epoch: 2, batch: 304, loss: 0.14428, accu: 0.94719, speed: 7.58 step/s\n",
      "global step 660, epoch: 2, batch: 314, loss: 0.09779, accu: 0.94779, speed: 7.62 step/s\n",
      "global step 670, epoch: 2, batch: 324, loss: 0.06792, accu: 0.94587, speed: 6.95 step/s\n",
      "global step 680, epoch: 2, batch: 334, loss: 0.12037, accu: 0.94590, speed: 6.90 step/s\n",
      "global step 690, epoch: 2, batch: 344, loss: 0.12555, accu: 0.94609, speed: 6.36 step/s\n",
      "global step 700, epoch: 3, batch: 8, loss: 0.08828, accu: 0.94735, speed: 6.53 step/s\n",
      "700 eval loss: 0.15707, accuracy: 0.93774\n",
      "global step 710, epoch: 3, batch: 18, loss: 0.09793, accu: 0.95781, speed: 1.81 step/s\n",
      "global step 720, epoch: 3, batch: 28, loss: 0.10369, accu: 0.95977, speed: 6.57 step/s\n",
      "global step 730, epoch: 3, batch: 38, loss: 0.09100, accu: 0.95807, speed: 7.10 step/s\n",
      "global step 740, epoch: 3, batch: 48, loss: 0.06428, accu: 0.95840, speed: 6.68 step/s\n",
      "global step 750, epoch: 3, batch: 58, loss: 0.20197, accu: 0.95734, speed: 7.29 step/s\n",
      "global step 760, epoch: 3, batch: 68, loss: 0.15122, accu: 0.95599, speed: 6.83 step/s\n",
      "global step 770, epoch: 3, batch: 78, loss: 0.10712, accu: 0.95580, speed: 6.80 step/s\n",
      "global step 780, epoch: 3, batch: 88, loss: 0.07757, accu: 0.95664, speed: 6.48 step/s\n",
      "global step 790, epoch: 3, batch: 98, loss: 0.08478, accu: 0.95738, speed: 6.83 step/s\n",
      "global step 800, epoch: 3, batch: 108, loss: 0.08689, accu: 0.95750, speed: 8.10 step/s\n",
      "800 eval loss: 0.17185, accuracy: 0.94118\n",
      "global step 810, epoch: 3, batch: 118, loss: 0.13745, accu: 0.95781, speed: 1.77 step/s\n",
      "global step 820, epoch: 3, batch: 128, loss: 0.14477, accu: 0.95859, speed: 6.69 step/s\n",
      "global step 830, epoch: 3, batch: 138, loss: 0.05389, accu: 0.95807, speed: 6.26 step/s\n",
      "global step 840, epoch: 3, batch: 148, loss: 0.11032, accu: 0.95918, speed: 7.10 step/s\n",
      "global step 850, epoch: 3, batch: 158, loss: 0.11166, accu: 0.95797, speed: 7.32 step/s\n",
      "global step 860, epoch: 3, batch: 168, loss: 0.14104, accu: 0.95755, speed: 6.85 step/s\n",
      "global step 870, epoch: 3, batch: 178, loss: 0.16706, accu: 0.95636, speed: 7.89 step/s\n",
      "global step 880, epoch: 3, batch: 188, loss: 0.07644, accu: 0.95684, speed: 7.32 step/s\n",
      "global step 890, epoch: 3, batch: 198, loss: 0.11056, accu: 0.95590, speed: 6.46 step/s\n",
      "global step 900, epoch: 3, batch: 208, loss: 0.18023, accu: 0.95477, speed: 7.46 step/s\n",
      "900 eval loss: 0.15710, accuracy: 0.93846\n",
      "global step 910, epoch: 3, batch: 218, loss: 0.08346, accu: 0.94453, speed: 1.80 step/s\n",
      "global step 920, epoch: 3, batch: 228, loss: 0.13192, accu: 0.94219, speed: 6.51 step/s\n",
      "global step 930, epoch: 3, batch: 238, loss: 0.17134, accu: 0.94766, speed: 6.94 step/s\n",
      "global step 940, epoch: 3, batch: 248, loss: 0.10857, accu: 0.95137, speed: 6.79 step/s\n",
      "global step 950, epoch: 3, batch: 258, loss: 0.14849, accu: 0.95250, speed: 7.39 step/s\n",
      "global step 960, epoch: 3, batch: 268, loss: 0.11649, accu: 0.95378, speed: 6.71 step/s\n",
      "global step 970, epoch: 3, batch: 278, loss: 0.18031, accu: 0.95279, speed: 6.72 step/s\n",
      "global step 980, epoch: 3, batch: 288, loss: 0.07466, accu: 0.95371, speed: 7.20 step/s\n",
      "global step 990, epoch: 3, batch: 298, loss: 0.12627, accu: 0.95234, speed: 8.25 step/s\n",
      "global step 1000, epoch: 3, batch: 308, loss: 0.11605, accu: 0.95234, speed: 6.79 step/s\n",
      "1000 eval loss: 0.15597, accuracy: 0.93828\n",
      "global step 1010, epoch: 3, batch: 318, loss: 0.14932, accu: 0.94922, speed: 1.78 step/s\n",
      "global step 1020, epoch: 3, batch: 328, loss: 0.10289, accu: 0.95312, speed: 6.95 step/s\n",
      "global step 1030, epoch: 3, batch: 338, loss: 0.10416, accu: 0.95182, speed: 6.56 step/s\n",
      "global step 1040, epoch: 4, batch: 2, loss: 0.11501, accu: 0.95126, speed: 6.45 step/s\n",
      "global step 1050, epoch: 4, batch: 12, loss: 0.03258, accu: 0.95545, speed: 6.11 step/s\n",
      "global step 1060, epoch: 4, batch: 22, loss: 0.09931, accu: 0.95743, speed: 6.92 step/s\n",
      "global step 1070, epoch: 4, batch: 32, loss: 0.06919, accu: 0.95917, speed: 6.85 step/s\n",
      "global step 1080, epoch: 4, batch: 42, loss: 0.10168, accu: 0.96048, speed: 6.77 step/s\n",
      "global step 1090, epoch: 4, batch: 52, loss: 0.05016, accu: 0.96123, speed: 6.91 step/s\n",
      "global step 1100, epoch: 4, batch: 62, loss: 0.06396, accu: 0.96105, speed: 7.06 step/s\n",
      "1100 eval loss: 0.17460, accuracy: 0.94136\n",
      "global step 1110, epoch: 4, batch: 72, loss: 0.15440, accu: 0.96406, speed: 1.81 step/s\n",
      "global step 1120, epoch: 4, batch: 82, loss: 0.06104, accu: 0.96172, speed: 7.55 step/s\n",
      "global step 1130, epoch: 4, batch: 92, loss: 0.07508, accu: 0.96276, speed: 8.12 step/s\n",
      "global step 1140, epoch: 4, batch: 102, loss: 0.14118, accu: 0.96367, speed: 6.50 step/s\n",
      "global step 1150, epoch: 4, batch: 112, loss: 0.11769, accu: 0.96484, speed: 7.03 step/s\n",
      "global step 1160, epoch: 4, batch: 122, loss: 0.09104, accu: 0.96341, speed: 6.72 step/s\n",
      "global step 1170, epoch: 4, batch: 132, loss: 0.10832, accu: 0.96317, speed: 6.72 step/s\n",
      "global step 1180, epoch: 4, batch: 142, loss: 0.05022, accu: 0.96318, speed: 8.31 step/s\n",
      "global step 1190, epoch: 4, batch: 152, loss: 0.08132, accu: 0.96432, speed: 7.31 step/s\n",
      "global step 1200, epoch: 4, batch: 162, loss: 0.18725, accu: 0.96398, speed: 6.45 step/s\n",
      "1200 eval loss: 0.17221, accuracy: 0.94136\n",
      "global step 1210, epoch: 4, batch: 172, loss: 0.13575, accu: 0.95625, speed: 1.77 step/s\n",
      "global step 1220, epoch: 4, batch: 182, loss: 0.04881, accu: 0.95977, speed: 6.92 step/s\n",
      "global step 1230, epoch: 4, batch: 192, loss: 0.09190, accu: 0.95990, speed: 6.99 step/s\n",
      "global step 1240, epoch: 4, batch: 202, loss: 0.12346, accu: 0.95996, speed: 6.78 step/s\n",
      "global step 1250, epoch: 4, batch: 212, loss: 0.17061, accu: 0.96016, speed: 7.48 step/s\n",
      "global step 1260, epoch: 4, batch: 222, loss: 0.12296, accu: 0.96172, speed: 7.10 step/s\n",
      "global step 1270, epoch: 4, batch: 232, loss: 0.10662, accu: 0.96261, speed: 6.37 step/s\n",
      "global step 1280, epoch: 4, batch: 242, loss: 0.17831, accu: 0.96211, speed: 6.92 step/s\n",
      "global step 1290, epoch: 4, batch: 252, loss: 0.14183, accu: 0.96137, speed: 6.46 step/s\n",
      "global step 1300, epoch: 4, batch: 262, loss: 0.12154, accu: 0.95891, speed: 6.36 step/s\n",
      "1300 eval loss: 0.16027, accuracy: 0.93973\n",
      "global step 1310, epoch: 4, batch: 272, loss: 0.05254, accu: 0.96875, speed: 1.75 step/s\n",
      "global step 1320, epoch: 4, batch: 282, loss: 0.13649, accu: 0.96406, speed: 7.20 step/s\n",
      "global step 1330, epoch: 4, batch: 292, loss: 0.04265, accu: 0.96615, speed: 6.87 step/s\n",
      "global step 1340, epoch: 4, batch: 302, loss: 0.12997, accu: 0.96387, speed: 7.52 step/s\n",
      "global step 1350, epoch: 4, batch: 312, loss: 0.16844, accu: 0.96500, speed: 7.34 step/s\n",
      "global step 1360, epoch: 4, batch: 322, loss: 0.06790, accu: 0.96406, speed: 7.95 step/s\n",
      "global step 1370, epoch: 4, batch: 332, loss: 0.15363, accu: 0.96217, speed: 6.73 step/s\n",
      "global step 1380, epoch: 4, batch: 342, loss: 0.14273, accu: 0.96211, speed: 6.72 step/s\n",
      "global step 1390, epoch: 5, batch: 6, loss: 0.11334, accu: 0.96307, speed: 6.78 step/s\n",
      "global step 1400, epoch: 5, batch: 16, loss: 0.11295, accu: 0.96333, speed: 7.06 step/s\n",
      "1400 eval loss: 0.17895, accuracy: 0.93973\n",
      "global step 1410, epoch: 5, batch: 26, loss: 0.14545, accu: 0.96641, speed: 1.74 step/s\n",
      "global step 1420, epoch: 5, batch: 36, loss: 0.09647, accu: 0.96445, speed: 6.72 step/s\n",
      "global step 1430, epoch: 5, batch: 46, loss: 0.04562, accu: 0.96641, speed: 6.34 step/s\n",
      "global step 1440, epoch: 5, batch: 56, loss: 0.19217, accu: 0.96816, speed: 7.66 step/s\n",
      "global step 1450, epoch: 5, batch: 66, loss: 0.07828, accu: 0.96750, speed: 7.47 step/s\n",
      "global step 1460, epoch: 5, batch: 76, loss: 0.05815, accu: 0.96732, speed: 6.35 step/s\n",
      "global step 1470, epoch: 5, batch: 86, loss: 0.06743, accu: 0.96775, speed: 7.11 step/s\n",
      "global step 1480, epoch: 5, batch: 96, loss: 0.05006, accu: 0.96768, speed: 6.38 step/s\n",
      "global step 1490, epoch: 5, batch: 106, loss: 0.08884, accu: 0.96658, speed: 6.90 step/s\n",
      "global step 1500, epoch: 5, batch: 116, loss: 0.09231, accu: 0.96703, speed: 7.08 step/s\n",
      "1500 eval loss: 0.17722, accuracy: 0.93919\n",
      "global step 1510, epoch: 5, batch: 126, loss: 0.05893, accu: 0.96953, speed: 1.79 step/s\n",
      "global step 1520, epoch: 5, batch: 136, loss: 0.10593, accu: 0.97305, speed: 6.13 step/s\n",
      "global step 1530, epoch: 5, batch: 146, loss: 0.12437, accu: 0.97109, speed: 6.39 step/s\n",
      "global step 1540, epoch: 5, batch: 156, loss: 0.10215, accu: 0.97148, speed: 6.25 step/s\n",
      "global step 1550, epoch: 5, batch: 166, loss: 0.13142, accu: 0.96969, speed: 6.63 step/s\n",
      "global step 1560, epoch: 5, batch: 176, loss: 0.10418, accu: 0.96849, speed: 6.35 step/s\n",
      "global step 1570, epoch: 5, batch: 186, loss: 0.08419, accu: 0.96897, speed: 7.99 step/s\n",
      "global step 1580, epoch: 5, batch: 196, loss: 0.10500, accu: 0.96777, speed: 6.69 step/s\n",
      "global step 1590, epoch: 5, batch: 206, loss: 0.06359, accu: 0.96788, speed: 7.56 step/s\n",
      "global step 1600, epoch: 5, batch: 216, loss: 0.06717, accu: 0.96820, speed: 7.39 step/s\n",
      "1600 eval loss: 0.17926, accuracy: 0.94027\n",
      "global step 1610, epoch: 5, batch: 226, loss: 0.18705, accu: 0.96172, speed: 1.82 step/s\n",
      "global step 1620, epoch: 5, batch: 236, loss: 0.14023, accu: 0.96094, speed: 6.78 step/s\n",
      "global step 1630, epoch: 5, batch: 246, loss: 0.08687, accu: 0.96224, speed: 7.71 step/s\n",
      "global step 1640, epoch: 5, batch: 256, loss: 0.18678, accu: 0.96211, speed: 6.41 step/s\n",
      "global step 1650, epoch: 5, batch: 266, loss: 0.05595, accu: 0.96281, speed: 6.63 step/s\n",
      "global step 1660, epoch: 5, batch: 276, loss: 0.17017, accu: 0.96497, speed: 7.57 step/s\n",
      "global step 1670, epoch: 5, batch: 286, loss: 0.10205, accu: 0.96451, speed: 6.86 step/s\n",
      "global step 1680, epoch: 5, batch: 296, loss: 0.06259, accu: 0.96523, speed: 7.41 step/s\n",
      "global step 1690, epoch: 5, batch: 306, loss: 0.17485, accu: 0.96528, speed: 7.12 step/s\n",
      "global step 1700, epoch: 5, batch: 316, loss: 0.08227, accu: 0.96555, speed: 6.83 step/s\n",
      "1700 eval loss: 0.17074, accuracy: 0.93991\n",
      "global step 1710, epoch: 5, batch: 326, loss: 0.17225, accu: 0.96016, speed: 1.84 step/s\n",
      "global step 1720, epoch: 5, batch: 336, loss: 0.06684, accu: 0.96523, speed: 6.54 step/s\n",
      "global step 1730, epoch: 5, batch: 346, loss: 0.27281, accu: 0.96477, speed: 6.54 step/s\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "import time\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "epochs = 5 # 训练轮次\n",
    "ckpt_dir = \"../Model\" #训练过程中保存模型参数的文件夹\n",
    "best_acc = 0\n",
    "best_step = 0\n",
    "global_step = 0 #迭代次数\n",
    "tic_train = time.time()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        input_ids, token_type_ids, labels = batch['input_ids'], batch['token_type_ids'], batch['labels']\n",
    "\n",
    "        # 计算模型输出、损失函数值、分类概率值、准确率\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        probs = F.softmax(logits, axis=1)\n",
    "        correct = metric.compute(probs, labels)\n",
    "        metric.update(correct)\n",
    "        acc = metric.accumulate()\n",
    "\n",
    "        # 每迭代10次，打印损失函数值、准确率、计算速度\n",
    "        global_step += 1\n",
    "        if global_step % 10 == 0:\n",
    "            print(\n",
    "                \"global step %d, epoch: %d, batch: %d, loss: %.5f, accu: %.5f, speed: %.2f step/s\"\n",
    "                % (global_step, epoch, step, loss, acc,\n",
    "                    10 / (time.time() - tic_train)))\n",
    "            tic_train = time.time()\n",
    "        \n",
    "        # 反向梯度回传，更新参数\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "\n",
    "        # 每迭代100次，评估当前训练的模型、保存当前模型参数和分词器的词表等\n",
    "        if global_step % 100 == 0:\n",
    "            save_dir = ckpt_dir\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            print(global_step, end=' ')\n",
    "            acc_eval = evaluate(model, criterion, metric, dev_data_loader)\n",
    "            if acc_eval > best_acc:\n",
    "                best_acc = acc_eval\n",
    "                best_step = global_step\n",
    "\n",
    "                model.save_pretrained(save_dir) # 保存模型参数\n",
    "                tokenizer.save_pretrained(save_dir) # 保存分词器数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T01:24:59.313184Z",
     "iopub.status.busy": "2022-10-18T01:24:59.312734Z",
     "iopub.status.idle": "2022-10-18T01:25:04.023802Z",
     "shell.execute_reply": "2022-10-18T01:25:04.023069Z",
     "shell.execute_reply.started": "2022-10-18T01:24:59.313155Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.15316, accuracy: 0.94281\n",
      "ERNIE 3.0-Medium 在开发集上表现为：0.9428054298642534\n"
     ]
    }
   ],
   "source": [
    "# 加载训练的模型最佳模型参数\n",
    "params_path = 'Model/model_state.pdparams'\n",
    "state_dict = paddle.load(params_path)\n",
    "model.set_dict(state_dict)\n",
    "\n",
    "print(f'ERNIE 3.0-Medium 在开发集上表现为：{evaluate(model, criterion, metric, dev_data_loader)}', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T01:25:04.025349Z",
     "iopub.status.busy": "2022-10-18T01:25:04.024897Z",
     "iopub.status.idle": "2022-10-18T01:25:04.030062Z",
     "shell.execute_reply": "2022-10-18T01:25:04.029469Z",
     "shell.execute_reply.started": "2022-10-18T01:25:04.025321Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 测试集数据预处理，利用分词器将文本转化为整数序列\n",
    "trans_func_test = functools.partial(preprocess_function, tokenizer=tokenizer, max_seq_length=256, is_test=True)\n",
    "test_ds_trans = test_ds.map(trans_func_test)\n",
    "\n",
    "# 进行采样组batch\n",
    "collate_fn_test = DataCollatorWithPadding(tokenizer)\n",
    "test_batch_sampler = BatchSampler(test_ds_trans, batch_size=32, shuffle=False)\n",
    "test_data_loader = DataLoader(dataset=test_ds_trans, batch_sampler=test_batch_sampler, collate_fn=collate_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T01:25:04.031333Z",
     "iopub.status.busy": "2022-10-18T01:25:04.030880Z",
     "iopub.status.idle": "2022-10-18T01:25:07.601683Z",
     "shell.execute_reply": "2022-10-18T01:25:07.601048Z",
     "shell.execute_reply.started": "2022-10-18T01:25:04.031310Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型预测分类结果\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "label_map = {0: '负面', 1: '正面'}\n",
    "results = []\n",
    "model.eval()\n",
    "for batch in test_data_loader:\n",
    "    input_ids, token_type_ids = batch['input_ids'], batch['token_type_ids']\n",
    "    logits = model(batch['input_ids'], batch['token_type_ids'])\n",
    "    probs = F.softmax(logits, axis=-1)\n",
    "    idx = paddle.argmax(probs, axis=1).numpy()\n",
    "    idx = idx.tolist()\n",
    "    preds = [label_map[i] for i in idx]\n",
    "    results.extend(preds)\n",
    "\n",
    "# 存储预测结果\n",
    "test_ds = load_dataset(read, data_path='./data/data172897/test.txt', lazy=False)\n",
    "res_dir = \"./results\"\n",
    "if not os.path.exists(res_dir):\n",
    "    os.makedirs(res_dir)\n",
    "with open(os.path.join(res_dir, \"result.tsv\"), 'w', encoding=\"utf8\") as f:\n",
    "    f.write(\"text\\tlabel\\tprediction\\n\")\n",
    "    for i, pred in enumerate(results):\n",
    "        f.write(test_ds[i]['text']+\"\\t\"+label_map[test_ds[i]['label']]+\"\\t\"+pred+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
