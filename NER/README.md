## 一、项目介绍

### 1、总体概要

​		本项目是一个典型的命名实体识别项目，命名实体识别是NLP中一项非常基础的任务，是指识别文本中具有特定意义的实体，主要包括人名、地名、机构名、专有名词等，是信息提取、问答系统、句法分析、机器翻译等众多NLP任务的重要基础工作。本项目使用网上已标记的命名实体识别数据集，使用`BiGRU`+`CRF`模型进行训练，最终能够实现对文本中具有特定意义的实体进行识别，并输出识别的结果。



### 2、数据集介绍

​		数据集采取了命名实体识别项目中常用的简历数据集进行训练，该数据集已经进行了标注，数据集

数据集的格式如下：

```
汉 B-RACE
族 E-RACE
， O
中 B-TITLE
共 M-TITLE
党 M-TITLE
员 E-TITLE

本 B-EDU
科 M-EDU
学 M-EDU
历 E-EDU
```

​		如上图所示：每一行中有一个字和一个标签，中间以空格进行分割，每句话之间以换行符（'\n'）为分割，对数据进行处理时，根据换行符的位置分割出每一句话，并通过空格将字符和标签区分。

该数据集的标签如下：

```
B-NAME
E-NAME
O
B-CONT
M-CONT
E-CONT
B-RACE
S-RACE
E-RACE
B-TITLE
M-TITLE
E-TITLE
B-EDU
```

该数据集属于`BMESO`标签体系，即以`B`（Begin）、`M`（Middle）、`E`（End）、`S`（Single）、 `O`（Other）为标签开口，分别代表开始、中间、结尾、单标签、其他标签，标签结尾的字符代表这个字符所属的标签种类，如`NAME`（姓名）、ORG（组织）、RACE（种族）等，如张三，标记为['B-NAME','E-NAME']。



### 3、模型介绍

![](.\data\model.png)

​		此处使用了`Bi-GRU+CRF`模型，使用 `PaddlePaddle` 来构建和训练模型，如上图所示，GRU的输出可以作为 CRF 的输入，最后 CRF 的输出作为模型整体的预测结果。



## 二、项目结构

```
├─data                    # 数据集
| ├─train.char			  # 训练集，用于数据的训练
| ├─dev.char              # 开发集，用于训练时的测试，以不断优化模型
| ├─test.char             # 测试集，用于对模型评估和验证
| ├─words.char            # 字符集合，包含了数据集中所有字符的集合
| └─labels.char           # 标签集合，包含了数据集中所有标签的集合
├─Model					  # 保存的模型
├─main.py                 # 主程序，负责整体程序的运行
├─build_model.py	      # 与模型构建，训练、评估和预测有关的程序
├─data_pre_processing.py  # 数据预处理程序，用于数据的读取、处理和封装
├─test_set_result.txt     # 测试集测试结果
├─requirements.txt        # 项目第三方库要求
└─README.md               # 项目描述文件		  
```

如上图所示，其中，`Model`文件夹下的模型因为太大，所以在项目打包时已经删除，若想运行程序，先使用以下命令：

```bash
python -m pip install -r requirements.txt
```

安装所需第三方库，再运行`main.py`文件。



## 三、使用的工具和库

开发语言：`Python3`

开发工具：`PyCharm`、`Jupyterlab`

第三方库：`paddle`和`paddlenlp`，详见`requirements.txt`



## 四、项目具体思路

### 1、数据预处理

​		数据预处理包含五个步骤，该项目使用函数去实现每一个步骤，然后通过函数的调用来实现数据的预处理，最后将处理后的可用于模型训练的数据返回出来，以用于模型的训练。

 #### （1）从文件读取数据

​		从文本文件读取数据集，并将其按照字符分割，存储到列表中，字符和标签分开。

```
原始数据：我 O              
		是 O							
		张 B-NAME
		三 E_NAME
		...
		
处理后的数据：[[['我','是','张','三','。'],['O','O','B-NAME','E-NAME','O'],[...],...]
```



#### （2）封装成`MapDataset`类型

​		使用`paddlenlp.datasets.MapDataset()`即可完成此步骤，封装成`MapDataset`的目的是为了接下来更好地处理数据。



#### （3）加载词典

​		从`words.char`和`labels.char`中加载数据，并将其处理成字典形式，即：

```
{"我":1,"是":2,"张":3,"三":4,...}
{"B-NAME":1,"M_NAME":2,"S-RACE":3,"O":4,...}
```

这样想做为了方便后面将将词转化为id，再进一步转化为词向量。



#### （4）将字符和标签转化为id

​		利用`（3）`步获得的字典，将`（1）`步读取到的数据映射为id，转化格式如下：

```
转换前：[['我','是','张','三','。'],['O','O','B-NAME','E-NAME','O']]
转换后：[['34','23','433','22','1'],['2','2','5','6','2']]
```



#### （5）构造`Dataloader`

​		每一句话因为长度不同，转化后的向量也是不同的，因为需要统一一下长度。此处采用的策略是以`OOV`字符来填充，对应的标签使用`O`来填充，最后会得到维度相同的向量。此外，因为数据集较多，不可能一下把所有数据塞进模型中进行训练，故需要进行分组，此处采用每32个数据为一组，即每个batch的大小为32，将数据分组之后塞进模型中进行训练。

​		以上描述使用`paddle.io.DataLoader`构建更为方便，故调用相关函数，分别构造关于训练集、验证集和测试集的`DataLoader`，构造完成后返回数据，该数据可以直接塞入模型中进行训练。



### 2、模型构建

​		模型的构建基于`paddle`深度学习框架，使用了面向对象的设计方法，封装了两个类，一个类是模型类，叫做`BiGRUWithCRF`，该类实现了模型的基本架构和数据流向。另一个类是模型调用类，叫做`Ner`，该类是对模型类的进一步封装，是为了在主函数中更好地调用模型完成命名实体识别任务。

#### （1）继承于`paddle.nn`基类搭建`BiGRU+CRF`模型

​		搭建模型框架较为简单，初始化每一个层，然后定义数据流向即可。初始化的层，包含向量层（Embedding层），该层加载了由百度百科数据集预训练的词向量模型，该层可以将输入的id序列转化为对应的词向量。接着便是经过一个`双向GRU`层，该模型根据输入的词向量进行训练，得到相应的模型，并输出一定结果。最后将预测的结果输入到`CRF`层，`CRF`的作用是优化解码序列，比如`BiGRU`模型对`我是张三`这句话的预测可能是`['O','O','E-NAME','B-NAME']`，虽然实现了正确预测，但却把名字的开始和结尾搞错了，`CRF`层就是为了纠正这个错误，以得到更为准确的分类结果。



#### （2）定义评价指标

​		这一步的目的是为了对模型进行评估，以在训练过程中不断调整权重，得到更优的模型。命名实体识别任务中常见的评价指标有精确率（Precision）、召回率（Recall） 和 综合评价指标（F1）。精确率，也叫查准率，由模型预测正确的个数除以模型总的预测的个数得到，关注模型预测出来的结果准不准。召回率，又叫查全率， 由模型预测正确的个数除以真实标签的个数得到，关注模型漏了哪些东西。综合评价指标，同时考虑 Precision 和 Recall ，是 Precision 和 Recall 的折中。此处便使用了这三种指标作为模型的评价指标，均通过调用`paddlepaddle`中的函数来实现。



##### （3）训练

​		建立模型的基础架构之后，只需要将数据集输入到模型中便可以进行训练，模型的训练需要用到两个数据集，即训练集和开发集，在`paddle`中，只需要将对应的数据集和评价指标传入到`fit`方法中，就可以开始训练，训练的部分结果如下图所示：

```bash
step 106/119 - loss: 0.0000e+00 - precision: 0.7840 - recall: 0.6850 - f1: 0.7312 - 3s/step
step 107/119 - loss: 1.6292 - precision: 0.7854 - recall: 0.6871 - f1: 0.7330 - 3s/step
step 108/119 - loss: 0.0109 - precision: 0.7868 - recall: 0.6893 - f1: 0.7348 - 3s/step
step 109/119 - loss: 10.3104 - precision: 0.7881 - recall: 0.6915 - f1: 0.7366 - 3s/step
step 110/119 - loss: 0.0000e+00 - precision: 0.7898 - recall: 0.6939 - f1: 0.7387 - 3s/step
step 111/119 - loss: 1.1919 - precision: 0.7902 - recall: 0.6955 - f1: 0.7399 - 3s/step
step 112/119 - loss: 1.2971 - precision: 0.7917 - recall: 0.6978 - f1: 0.7418 - 3s/step
step 113/119 - loss: 0.0000e+00 - precision: 0.7927 - recall: 0.6992 - f1: 0.7430 - 3s/step
step 114/119 - loss: 0.2072 - precision: 0.7939 - recall: 0.7008 - f1: 0.7445 - 3s/step
step 115/119 - loss: 24.9918 - precision: 0.7955 - recall: 0.7026 - f1: 0.7462 - 3s/step
step 116/119 - loss: 1.4333 - precision: 0.7967 - recall: 0.7047 - f1: 0.7479 - 3s/step
step 117/119 - loss: 0.0000e+00 - precision: 0.7980 - recall: 0.7063 - f1: 0.7493 - 3s/step
step 118/119 - loss: 0.1471 - precision: 0.7993 - recall: 0.7080 - f1: 0.7509 - 3s/step
step 119/119 - loss: 0.0000e+00 - precision: 0.8005 - recall: 0.7098 - f1: 0.7524 - 3s/step
```

​		如上所示，训练过程中，`loss`在逐渐减小，三种评价指标也在上升，可见该模型是收敛的，效果较为不错。训练结束后，模型的`precision`、`recall`和`f1`已达0.8005、0.7098和9.7524，符合预期。



#### （4）评估

​		训练过程中用到了训练集和开发集，训练完成后，使用测试集对模型进行进一步评估，评估的结果如下：

```bash
step  1/14 - loss: 0.0000e+00 - precision: 0.9281 - recall: 0.9344 - f1: 0.9312 - 910ms/step
step  2/14 - loss: 0.0000e+00 - precision: 0.9296 - recall: 0.9350 - f1: 0.9323 - 1s/step
step  3/14 - loss: 0.0000e+00 - precision: 0.9417 - recall: 0.9348 - f1: 0.9382 - 1s/step
step  4/14 - loss: 4.3553 - precision: 0.9275 - recall: 0.9480 - f1: 0.9376 - 1s/step
step  5/14 - loss: 3.6332 - precision: 0.9269 - recall: 0.9483 - f1: 0.9375 - 1s/step
step  6/14 - loss: 0.0000e+00 - precision: 0.9212 - recall: 0.9463 - f1: 0.9336 - 1s/step
step  7/14 - loss: 0.0000e+00 - precision: 0.9107 - recall: 0.9341 - f1: 0.9223 - 1s/step
step  8/14 - loss: 0.0000e+00 - precision: 0.9080 - recall: 0.9321 - f1: 0.9199 - 1s/step
step  9/14 - loss: 5.0697 - precision: 0.9162 - recall: 0.9376 - f1: 0.9268 - 1s/step
step 10/14 - loss: 0.0000e+00 - precision: 0.9159 - recall: 0.9385 - f1: 0.9271 - 967ms/step
step 11/14 - loss: 80.8093 - precision: 0.9069 - recall: 0.9208 - f1: 0.9138 - 1s/step
step 12/14 - loss: 1.5494 - precision: 0.9089 - recall: 0.9242 - f1: 0.9165 - 984ms/step
step 13/14 - loss: 0.0000e+00 - precision: 0.9061 - recall: 0.9272 - f1: 0.9166 - 1s/step
step 14/14 - loss: 5.3732 - precision: 0.9078 - recall: 0.9248 - f1: 0.9162 - 974ms/step
```

​		如上所示，训练好的模型对测试集的评价指标`precision`、`recall`和`f1`已达0.9078、0.9248和0.9162，高于训练过程中的指标，可见模型对于测试集的评估是比较理想的，下面进一步对测试集进行预测，并将预测的结果直观地显示出来。



### 3、利用模型对测试集进行预测

​		训练好的模型，就可以进行预测，本次采用测试机对训练的模型进行预测，当输入一个句子进入模型之后，模型并不会输出相对应的标签，而是输出相应标签的id，而且经过一系列解码之后才能够得到，解码的详细函数见具体程序，使用训练好的模型对测试机的预测结果如下，完整的预测结果请见项目目录下的`test_set_result.txt`文件：

```
('常建良', 'NAME')('，', 'O')('男', 'O')('，', 'O')
('清华大学公共管理学院', 'ORG')('MPA', 'TITLE')('。', 'O')
('美国明尼苏达大学', 'NAME')('博士', 'EDU')('后', 'O')('；', 'O')
('现', 'O')('任', 'O')('大连市电力发展公司', 'ORG')('总经理', 'TITLE')('。', 'O')
('曾', 'O')('任', 'O')('大连市电力发展公司', 'ORG')('副总经理', 'TITLE')('。', 'O')
('7', 'O')('月', 'O')('进', 'O')('入', 'O')('无锡威孚高科技集团股份有限公司', 'ORG')('。', 'O')
```



## 五、总结

​		命名实体识别是NLP中非常基础的任务，但因为我对深度学习知识掌握的不熟练、对NLP处理方法的不了解和对深度学习框架的不熟悉，导致我做这个项目花费了很长的时间，远远超出了自己原本的计划。但通过查找资料，观看相关的视频，总算是完成了项目，并且对深度学习、自然语言处理和深度学习框架有了一定的了解，为之后做NLP项目提供了基础。今后我一定会更加地努力，去学习和掌握更多的知识，不断地提高自己的能力和水平。

